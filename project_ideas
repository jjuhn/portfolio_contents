1. https://www.quora.com/What-are-some-artificial-neural-network-project-ideas-for-undergraduates 
    - Korean website: https://www.edwith.org/deeplearningchoi/ 
    - https://github.com/zzsza/Deep_Learning_starting_with_the_latest_papers
    
2. Bayesian modeling tutorial?
    
    - Dependent vs Independent sampling
        - independent sampling: limited to special cases, effective only in low dimensions, require special tailoring for efficiency(time consuming)
        - dependent sampling: wider variety of simulation methods, complex, high dimensional but requires more samples for a given accuracy
        
    - Markov chain explanation(what is the purpose? where it is used?
    - MCMC explanation
        - Good paper: http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.13.7133&rep=rep1&type=pd
        - make one in python and one for R. 
            - python: https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/
            - R: I know how to do it. hubble telescope data. 
        - Gibbs Sampling
        - Metropolis algorithms (simplify with example) 
        - Metropolis Hastings
    - Practical MCMC in R.
        - JAGS(DAGS)
        - Decisions: how many chains?, starting point?, converged?, transient?, which iterates to use?, how many iterates do we need?
            - run several independent chains from different sparse starting points(3 to 5 chains)
            - overdispersed starting point is much better: multiple modes detection is easier, so as convergence diagnostics 
            - in hierarchical model, only the top level hyperparameter should be initialized
            - automatic tuning: **Adaptation**, use the tuning but discard the initial run 
            - convergence: the good chain = posterior is the limiting distribution
3. Check out datastudio by google for visualization project 
    - what to visualize? maybe some sort of data science related algorithms. apriori?
4. Linear Regression using R (DONE, house price prediction project)
5. Linear Regression using R in MCMC approach. 
6. What is the difference? Which is better? 
7. About Kaggle Competition: 
     - Algorithms that are often used 
        - XGBoost
        - LightGBM
        - Catboost
        - StackNet
     - HOW TO WIN IN KAGGLE:  https://www.coursera.org/learn/competitive-data-science/  
     - PyCon Korea:  https://www.slideshare.net/yeonminkim/pycon-korea-2018-kaggle-tutorialkaggle-break 
8. List of possible interview questions
9. Personal Diary about my gap year: study, things I did, parenting etc.
10. Recent Paper Reviews:
    - Using Bayesian Aldrich-Mckelvey Scaling to study citizens' ideological preferences and perceptions
11. Fix the current portfolio website
    - R markdown/ ipython notebook incorporation
12. Prioritize this list 
13. Teaching materials: https://intellipaat.com/data-scientist-course-training/?utm_source=Quora&utm_medium=Paid&utm_campaign=Data%20Science-US-Topic-Image#about-course
14. Everybody lies : book review and learn about the big data 





        
        
